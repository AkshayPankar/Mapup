{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Car Matrix Generation\n",
    "Under the function named generate_car_matrix write a logic that takes the dataset-1.csv as a DataFrame. Return a new DataFrame that follows the following rules:\n",
    "\n",
    "values from id_2 as columns\n",
    "values from id_1 as index\n",
    "dataframe should have values from car column\n",
    "diagonal values should be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_car_matrix(dataset):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # Pivot the DataFrame to create the desired matrix\n",
    "    car_matrix = df.pivot(index='id_1', columns='id_2', values='car').fillna(0)\n",
    "\n",
    "    # Set the diagonal values to 0\n",
    "    car_matrix.values[[range(len(car_matrix))]*2] = 0\n",
    "\n",
    "    return car_matrix\n",
    "\n",
    "# Replace 'dataset-1.csv' with the actual file path\n",
    "result_matrix = generate_car_matrix('dataset-1.csv')\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Car Type Count Calculation\n",
    "Create a Python function named get_type_count that takes the dataset-1.csv as a DataFrame. Add a new categorical column car_type based on values of the column car:\n",
    "\n",
    "low for values less than or equal to 15,\n",
    "medium for values greater than 15 and less than or equal to 25,\n",
    "high for values greater than 25.\n",
    "Calculate the count of occurrences for each car_type category and return the result as a dictionary. Sort the dictionary alphabetically based on keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_type_count(dataset):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # Add a new categorical column 'car_type'\n",
    "    conditions = [\n",
    "        (df['car'] <= 15),\n",
    "        (df['car'] > 15) & (df['car'] <= 25),\n",
    "        (df['car'] > 25)\n",
    "    ]\n",
    "\n",
    "    choices = ['low', 'medium', 'high']\n",
    "    df['car_type'] = pd.Series(np.select(conditions, choices, default=np.nan))\n",
    "\n",
    "    # Calculate the count of occurrences for each car_type category\n",
    "    type_count = df['car_type'].value_counts().to_dict()\n",
    "\n",
    "    # Sort the dictionary alphabetically based on keys\n",
    "    type_count = {k: type_count[k] for k in sorted(type_count)}\n",
    "\n",
    "    return type_count\n",
    "\n",
    "# Replace 'dataset-1.csv' with the actual file path\n",
    "result_type_count = get_type_count('dataset-1.csv')\n",
    "print(result_type_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Bus Count Index Retrieval\n",
    "Create a Python function named get_bus_indexes that takes the dataset-1.csv as a DataFrame. The function should identify and return the indices as a list (sorted in ascending order) where the bus values are greater than twice the mean value of the bus column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_bus_indexes(dataset):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # Calculate the mean value of the 'bus' column\n",
    "    bus_mean = df['bus'].mean()\n",
    "\n",
    "    # Identify indices where the 'bus' values are greater than twice the mean\n",
    "    bus_indexes = df[df['bus'] > 2 * bus_mean].index.tolist()\n",
    "\n",
    "    # Sort the indices in ascending order\n",
    "    bus_indexes.sort()\n",
    "\n",
    "    return bus_indexes\n",
    "\n",
    "# Replace 'dataset-1.csv' with the actual file path\n",
    "result_bus_indexes = get_bus_indexes('dataset-1.csv')\n",
    "print(result_bus_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Route Filtering\n",
    "Create a python function filter_routes that takes the dataset-1.csv as a DataFrame. The function should return the sorted list of values of column route for which the average of values of truck column is greater than 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_routes(dataset):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # Calculate the average of values in the 'truck' column for each route\n",
    "    avg_truck_by_route = df.groupby('route')['truck'].mean()\n",
    "\n",
    "    # Filter routes where the average truck value is greater than 7\n",
    "    filtered_routes = avg_truck_by_route[avg_truck_by_route > 7].index.tolist()\n",
    "\n",
    "    # Sort the list of routes in ascending order\n",
    "    filtered_routes.sort()\n",
    "\n",
    "    return filtered_routes\n",
    "\n",
    "# Replace 'dataset-1.csv' with the actual file path\n",
    "result_filtered_routes = filter_routes('dataset-1.csv')\n",
    "print(result_filtered_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Matrix Value Modification\n",
    "Create a Python function named multiply_matrix that takes the resulting DataFrame from Question 1, as input and modifies each value according to the following logic:\n",
    "\n",
    "If a value in the DataFrame is greater than 20, multiply those values by 0.75,\n",
    "If a value is 20 or less, multiply those values by 1.25.\n",
    "The function should return the modified DataFrame which has values rounded to 1 decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def multiply_matrix(car_matrix):\n",
    "    # Apply the specified logic to modify matrix values\n",
    "    modified_matrix = car_matrix.applymap(lambda x: x * 0.75 if x > 20 else x * 1.25)\n",
    "\n",
    "    # Round the values to 1 decimal place\n",
    "    modified_matrix = modified_matrix.round(1)\n",
    "\n",
    "    return modified_matrix\n",
    "\n",
    "# Assuming 'result_matrix' is the DataFrame obtained from Question 1\n",
    "# Replace 'result_matrix' with the actual DataFrame variable\n",
    "result_matrix_modified = multiply_matrix(result_matrix)\n",
    "print(result_matrix_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Time Check\n",
    "You are given a dataset, dataset-2.csv, containing columns id, id_2, and timestamp (startDay, startTime, endDay, endTime). The goal is to verify the completeness of the time data by checking whether the timestamps for each unique (id, id_2) pair cover a full 24-hour period (from 12:00:00 AM to 11:59:59 PM) and span all 7 days of the week (from Monday to Sunday).\n",
    "\n",
    "Create a function that accepts dataset-2.csv as a DataFrame and returns a boolean series that indicates if each (id, id_2) pair has incorrect timestamps. The boolean series must have multi-index (id, id_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_time_completeness(df):\n",
    "    # Combine 'startDay' and 'startTime' to create a 'start_datetime' column\n",
    "    df['start_datetime'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'])\n",
    "\n",
    "    # Combine 'endDay' and 'endTime' to create an 'end_datetime' column\n",
    "    df['end_datetime'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'])\n",
    "\n",
    "    # Check if each (id, id_2) pair covers a full 24-hour period and spans all 7 days\n",
    "    completeness_check = (\n",
    "        df.groupby(['id', 'id_2'])\n",
    "        .apply(\n",
    "            lambda group: (\n",
    "                (group['start_datetime'].min().time() == pd.Timestamp('00:00:00').time()) and\n",
    "                (group['end_datetime'].max().time() == pd.Timestamp('23:59:59').time()) and\n",
    "                (group['start_datetime'].min().day_name() == 'Monday') and\n",
    "                (group['end_datetime'].max().day_name() == 'Sunday')\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return completeness_check\n",
    "\n",
    "# Replace 'dataset-2.csv' with the actual file path\n",
    "df_dataset_2 = pd.read_csv('dataset-2.csv')\n",
    "result_time_completeness = check_time_completeness(df_dataset_2)\n",
    "print(result_time_completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Task 2\n",
    "Question 1: Distance Matrix Calculation\n",
    "Create a function named calculate_distance_matrix that takes the dataset-3.csv as input and generates a DataFrame representing distances between IDs.\n",
    "\n",
    "The resulting DataFrame should have cumulative distances along known routes, with diagonal values set to 0. If distances between toll locations A to B and B to C are known, then the distance from A to C should be the sum of these distances. Ensure the matrix is symmetric, accounting for bidirectional distances between toll locations (i.e. A to B is equal to B to A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_distance_matrix(dataset_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Create a DataFrame for distances with IDs as indices and columns\n",
    "    distance_matrix = pd.DataFrame(index=df['ID'].unique(), columns=df['ID'].unique())\n",
    "\n",
    "    # Initialize the distance matrix with zeros\n",
    "    distance_matrix = distance_matrix.fillna(0)\n",
    "\n",
    "    # Iterate over rows in the dataset to calculate cumulative distances\n",
    "    for index, row in df.iterrows():\n",
    "        start_id, end_id, distance = row['Start_ID'], row['End_ID'], row['Distance']\n",
    "\n",
    "        # Update the distance matrix with bidirectional distances\n",
    "        distance_matrix.at[start_id, end_id] += distance\n",
    "        distance_matrix.at[end_id, start_id] += distance\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "# Replace 'dataset-3.csv' with the actual file path\n",
    "result_distance_matrix = calculate_distance_matrix('dataset-3.csv')\n",
    "print(result_distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Unroll Distance Matrix\n",
    "Create a function unroll_distance_matrix that takes the DataFrame created in Question 1. The resulting DataFrame should have three columns: columns id_start, id_end, and distance.\n",
    "\n",
    "All the combinations except for same id_start to id_end must be present in the rows with their distance values from the input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def unroll_distance_matrix(distance_matrix):\n",
    "    # Create an empty DataFrame to store unrolled distance values\n",
    "    unrolled_distances = pd.DataFrame(columns=['id_start', 'id_end', 'distance'])\n",
    "\n",
    "    # Iterate over the rows of the distance matrix\n",
    "    for id_start in distance_matrix.index:\n",
    "        for id_end in distance_matrix.columns:\n",
    "            # Skip rows where id_start is equal to id_end\n",
    "            if id_start == id_end:\n",
    "                continue\n",
    "\n",
    "            # Extract the distance value from the distance matrix\n",
    "            distance = distance_matrix.at[id_start, id_end]\n",
    "\n",
    "            # Append a row to the unrolled_distances DataFrame\n",
    "            unrolled_distances = unrolled_distances.append({\n",
    "                'id_start': id_start,\n",
    "                'id_end': id_end,\n",
    "                'distance': distance\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    return unrolled_distances\n",
    "\n",
    "# Assuming result_distance_matrix is the DataFrame from Question 1\n",
    "# Replace result_distance_matrix with the actual DataFrame variable\n",
    "result_unrolled_distances = unroll_distance_matrix(result_distance_matrix)\n",
    "print(result_unrolled_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Finding IDs within Percentage Threshold\n",
    "Create a function find_ids_within_ten_percentage_threshold that takes the DataFrame created in Question 2 and a reference value from the id_start column as an integer.\n",
    "\n",
    "Calculate average distance for the reference value given as an input and return a sorted list of values from id_start column which lie within 10% (including ceiling and floor) of the reference value's average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_ids_within_ten_percentage_threshold(df_distances, reference_value):\n",
    "    # Filter rows with the specified reference value as id_start\n",
    "    reference_rows = df_distances[df_distances['id_start'] == reference_value]\n",
    "\n",
    "    # Calculate the average distance for the reference value\n",
    "    average_distance = reference_rows['distance'].mean()\n",
    "\n",
    "    # Calculate the 10% threshold\n",
    "    threshold_low = 0.9 * average_distance\n",
    "    threshold_high = 1.1 * average_distance\n",
    "\n",
    "    # Filter rows within the 10% threshold\n",
    "    filtered_rows = df_distances[\n",
    "        (df_distances['distance'] >= threshold_low) &\n",
    "        (df_distances['distance'] <= threshold_high)\n",
    "    ]\n",
    "\n",
    "    # Get unique values from the id_start column and sort the list\n",
    "    result_ids = sorted(filtered_rows['id_start'].unique().tolist())\n",
    "\n",
    "    return result_ids\n",
    "\n",
    "# Assuming result_unrolled_distances is the DataFrame from Question 2\n",
    "# Replace result_unrolled_distances with the actual DataFrame variable\n",
    "result_reference_ids = find_ids_within_ten_percentage_threshold(result_unrolled_distances, reference_value=1)\n",
    "print(result_reference_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function calculate_toll_rate that takes the DataFrame created in Question 2 as input and calculates toll rates based on vehicle types.\n",
    "\n",
    "The resulting DataFrame should add 5 columns to the input DataFrame: moto, car, rv, bus, and truck with their respective rate coefficients. The toll rates should be calculated by multiplying the distance with the given rate coefficients for each vehicle type:\n",
    "\n",
    "0.8 for moto\n",
    "1.2 for car\n",
    "1.5 for rv\n",
    "2.2 for bus\n",
    "3.6 for truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_toll_rate(df_distances):\n",
    "    # Define rate coefficients for each vehicle type\n",
    "    rate_coefficients = {'moto': 0.8, 'car': 1.2, 'rv': 1.5, 'bus': 2.2, 'truck': 3.6}\n",
    "\n",
    "    # Add new columns for each vehicle type\n",
    "    for vehicle_type, rate_coefficient in rate_coefficients.items():\n",
    "        df_distances[vehicle_type] = df_distances['distance'] * rate_coefficient\n",
    "\n",
    "    return df_distances\n",
    "\n",
    "# Assuming result_unrolled_distances is the DataFrame from Question 2\n",
    "# Replace result_unrolled_distances with the actual DataFrame variable\n",
    "result_distances_with_toll = calculate_toll_rate(result_unrolled_distances)\n",
    "print(result_distances_with_toll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Calculate Time-Based Toll Rates\n",
    "Create a function named calculate_time_based_toll_rates that takes the DataFrame created in Question 3 as input and calculates toll rates for different time intervals within a day.\n",
    "\n",
    "The resulting DataFrame should have these five columns added to the input: start_day, start_time, end_day, and end_time.\n",
    "\n",
    "start_day, end_day must be strings with day values (from Monday to Sunday in proper case)\n",
    "start_time and end_time must be of type datetime.time() with the values from time range given below.\n",
    "Modify the values of vehicle columns according to the following time ranges:\n",
    "\n",
    "Weekdays (Monday - Friday):\n",
    "\n",
    "From 00:00:00 to 10:00:00: Apply a discount factor of 0.8\n",
    "From 10:00:00 to 18:00:00: Apply a discount factor of 1.2\n",
    "From 18:00:00 to 23:59:59: Apply a discount factor of 0.8\n",
    "Weekends (Saturday and Sunday):\n",
    "\n",
    "Apply a constant discount factor of 0.7 for all times.\n",
    "For each unique (id_start, id_end) pair, cover a full 24-hour period (from 12:00:00 AM to 11:59:59 PM) and span all 7 days of the week (from Monday to Sunday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_time_based_toll_rates(df):\n",
    "    # Define time ranges and discount factors for weekdays and weekends\n",
    "    weekday_time_ranges = [\n",
    "        ('00:00:00', '10:00:00', 0.8),\n",
    "        ('10:00:00', '18:00:00', 1.2),\n",
    "        ('18:00:00', '23:59:59', 0.8)\n",
    "    ]\n",
    "    weekend_discount_factor = 0.7\n",
    "\n",
    "    # Create an empty DataFrame to store the results\n",
    "    result_df = pd.DataFrame(columns=['id_start', 'id_end', 'start_day', 'start_time', 'end_day', 'end_time'])\n",
    "\n",
    "    # Iterate over unique (id_start, id_end) pairs\n",
    "    for (id_start, id_end), group_df in df.groupby(['id_start', 'id_end']):\n",
    "        # Ensure each pair covers a full 24-hour period and spans all 7 days of the week\n",
    "        unique_days = pd.to_datetime(group_df['start_day']).dt.day_name().unique()\n",
    "        unique_times = pd.to_datetime(group_df['start_time']).dt.time.unique()\n",
    "\n",
    "        if len(unique_days) == 7 and len(unique_times) == 1:\n",
    "            # Assign values for each day of the week and time range\n",
    "            for day in unique_days:\n",
    "                for start_time, end_time, discount_factor in weekday_time_ranges:\n",
    "                    start_datetime = pd.to_datetime('2023-01-01 ' + start_time)\n",
    "                    end_datetime = pd.to_datetime('2023-01-01 ' + end_time)\n",
    "\n",
    "                    result_df = result_df.append({\n",
    "                        'id_start': id_start,\n",
    "                        'id_end': id_end,\n",
    "                        'start_day': day,\n",
    "                        'start_time': start_datetime.time(),\n",
    "                        'end_day': day,\n",
    "                        'end_time': end_datetime.time(),\n",
    "                        'discount_factor': discount_factor\n",
    "                    }, ignore_index=True)\n",
    "        else:\n",
    "            # Assign values for weekends\n",
    "            for day in unique_days:\n",
    "                start_datetime = pd.to_datetime('2023-01-01 00:00:00')\n",
    "                end_datetime = pd.to_datetime('2023-01-01 23:59:59')\n",
    "\n",
    "                result_df = result_df.append({\n",
    "                    'id_start': id_start,\n",
    "                    'id_end': id_end,\n",
    "                    'start_day': day,\n",
    "                    'start_time': start_datetime.time(),\n",
    "                    'end_day': day,\n",
    "                    'end_time': end_datetime.time(),\n",
    "                    'discount_factor': weekend_discount_factor\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Assuming result_unrolled_distances is the DataFrame from Question 3\n",
    "# Replace result_unrolled_distances with the actual DataFrame variable\n",
    "result_time_based_toll_rates = calculate_time_based_toll_rates(result_unrolled_distances)\n",
    "print(result_time_based_toll_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
